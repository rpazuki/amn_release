{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing worker spawn time...\n"
     ]
    }
   ],
   "source": [
    "# Quick test: How long does it take to spawn workers?\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "def dummy_task(x):\n",
    "    \"\"\"Minimal function to test worker spawn time\"\"\"\n",
    "    return x * 2\n",
    "\n",
    "print(\"Testing worker spawn time...\")\n",
    "start = time.time()\n",
    "with Pool(4) as p:\n",
    "    p.map(dummy_task, range(4))\n",
    "end = time.time()\n",
    "print(f\"Time to spawn 4 workers with dummy task: {end-start:.2f} seconds\")\n",
    "print(\"If this takes >30 seconds, the issue is Python/conda environment, not your code\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parallel processing of 13 experiments with 4 workers\n",
      "Log files will be created in c:\\Users\\rh2310\\projects\\amn_release\\logs/ directory\n",
      "Starting at: 2025-12-03 16:17:29\n",
      "Workers are being spawned and libraries loaded...\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "paralell_level = 4\n",
    "\n",
    "def create_random_medium_cobra(expname:str):    \n",
    "    \"\"\"\n",
    "    Simplified wrapper - all parameters hardcoded to reduce pickling\n",
    "    Import heavy libraries only once per worker\n",
    "    \"\"\"\n",
    "    \n",
    "    # These imports happen once per worker process (not per function call)\n",
    "    # But they're still inside the function to avoid module-level pickling\n",
    "    import pandas as pd\n",
    "    from Library.Build_Dataset_lite import TrainingSet\n",
    "    \n",
    "    # Hardcoded parameters\n",
    "    cobraname = 'iML1515_duplicated_Lab_Data'\n",
    "    mediumname = 'df_amn_dataset_levels'\n",
    "    mediumbound = 'UB'\n",
    "    exp_df_name = 'df_amn_dataset'\n",
    "    method = 'pFBA'\n",
    "    size_i = 100\n",
    "    reduce = True\n",
    "    verbose = True\n",
    "    DIRECTORY = './'\n",
    "    \n",
    "    # Setup logging\n",
    "    log_dir = './logs'\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')\n",
    "    log_file = f'{log_dir}/{expname}_{timestamp}.log'\n",
    "    \n",
    "    log_f = open(log_file, 'w', buffering=1)\n",
    "    \n",
    "    def log(message):\n",
    "        log_f.write(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - {message}\\n\")\n",
    "        log_f.flush()\n",
    "    \n",
    "    try:\n",
    "        log(f\"Starting processing for {expname}\")\n",
    "        \n",
    "        # Get X from experimental data set\n",
    "        cobrafile = DIRECTORY+'Dataset_input/'+cobraname\n",
    "        exp_data_path = f\"H:/ROBOT_SCIENTIST/E_coli/Growth_rates/2025-10-31-27/processed/no_replicates/{expname}/AMN_dataset/\"\n",
    "        expfile = exp_data_path + exp_df_name\n",
    "\n",
    "        log(f\"Reading experimental data from {expfile}\")\n",
    "        df_exp = pd.read_csv(expfile+\".csv\")\n",
    "        mediumsize = len(df_exp.columns) - 1\n",
    "        \n",
    "        log(f\"Creating TrainingSet with mediumsize={mediumsize}\")\n",
    "        parameter = TrainingSet(cobraname=cobrafile, \n",
    "                                mediumname=expfile, \n",
    "                                mediumbound=mediumbound, \n",
    "                                mediumsize=mediumsize, \n",
    "                                method='EXP',verbose=False)\n",
    "        X = parameter.X.copy()\n",
    "        log(f\"X shape: {X.shape}\")\n",
    "\n",
    "        # Get other parameters from medium file\n",
    "        mediumfile = exp_data_path + mediumname\n",
    "        log(f\"Reading medium file from {mediumfile}\")\n",
    "        parameter = TrainingSet(cobraname=cobrafile, \n",
    "                                mediumname=mediumfile, \n",
    "                                mediumbound=mediumbound, \n",
    "                                method=method, verbose=False)\n",
    "\n",
    "        # Create varmed list\n",
    "        log(\"Creating variable medium list\")\n",
    "        varmed = {}\n",
    "        for i in range(X.shape[0]):\n",
    "            varmed[i] = []\n",
    "            for j in range(X.shape[1]):\n",
    "                if parameter.levmed[j] > 1 and X[i,j] > 0:\n",
    "                    varmed[i].append(parameter.medium[j])\n",
    "        varmed = list(varmed.values())\n",
    "        log(f\"Variable medium created with {len(varmed)} entries\")\n",
    "        \n",
    "        # Get COBRA training set\n",
    "        log(f\"Starting COBRA training set generation for {X.shape[0]} samples with size_i={size_i}\")\n",
    "        for i in range(X.shape[0]): \n",
    "            log(f\"Processing sample {i+1}/{X.shape[0]}\")\n",
    "            parameter.get(sample_size=size_i, varmed=varmed[i], verbose=verbose, reduce=reduce) \n",
    "            log(f\"Sample {i+1}/{X.shape[0]} completed\")\n",
    "\n",
    "        # Saving file\n",
    "        trainingfile = DIRECTORY+'Dataset_model/'+expname+'_'+parameter.mediumbound\n",
    "        log(f\"Saving training file to {trainingfile}\")\n",
    "        parameter.save(trainingfile, reduce=reduce)\n",
    "        log(f\"Successfully completed processing for {expname}\")\n",
    "        \n",
    "        log_f.close()\n",
    "        return f\"{expname}: SUCCESS\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        log(f\"ERROR processing {expname}: {str(e)}\")\n",
    "        log(traceback.format_exc())\n",
    "        log_f.close()\n",
    "        return f\"{expname}: FAILED - {str(e)}\"\n",
    "\n",
    "\n",
    "# Main execution\n",
    "if __name__ == '__main__' or 'ipykernel' in sys.modules:\n",
    "    # Create logs directory\n",
    "    log_dir = './logs'\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    expnames = os.listdir('H:/ROBOT_SCIENTIST/E_coli/Growth_rates/2025-10-31-27/processed/no_replicates')\n",
    "\n",
    "    print(f\"Starting parallel processing of {len(expnames)} experiments with {paralell_level} workers\")\n",
    "    print(f\"Log files will be created in {os.path.abspath(log_dir)}/ directory\")\n",
    "    print(f\"Starting at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(\"Workers are being spawned...\")\n",
    "    print(\"(This may take 30-60 seconds for workers to load libraries)\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Use Pool without wrapper function\n",
    "    with Pool(paralell_level) as p:\n",
    "        results = p.map(create_random_medium_cobra, expnames)\n",
    "\n",
    "    print(f\"\\nCompleted at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(\"\\n=== Processing Summary ===\")\n",
    "    for result in results:\n",
    "        print(result)\n",
    "    print(f\"Check individual log files in {os.path.abspath(log_dir)}/ for detailed progress\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T16:09:13.689226Z",
     "iopub.status.busy": "2025-11-12T16:09:13.689226Z",
     "iopub.status.idle": "2025-11-12T16:09:31.984153Z",
     "shell.execute_reply": "2025-11-12T16:09:31.984047Z",
     "shell.execute_reply.started": "2025-11-12T16:09:13.689226Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduced numbers of metabolites and reactions: 1078 507\n",
      "./Dataset_model/mediabotJLF1_UB\n",
      "model file name: ./Dataset_model/mediabotJLF1_UB\n",
      "reduced model: True\n",
      "medium file name: H:/ROBOT_SCIENTIST/E_coli/Growth_rates/2025-10-31-27/processed/no_replicates/mediabotJLF1/AMN_dataset/df_amn_dataset_levels\n",
      "medium bound: UB\n",
      "list of reactions in objective: ['BIOMASS_Ec_iML1515_core_75p37M']\n",
      "method: pFBA\n",
      "trainingsize: 66\n",
      "list of medium reactions: 34\n",
      "list of medium levels: 34\n",
      "list of medium values: 34\n",
      "ratio of variable medium turned on: 0.0\n",
      "list of measured reactions: 507\n",
      "Stoichiometric matrix (1078, 507)\n",
      "Boundary matrix from reactions to medium: (34, 507)\n",
      "Measurement matrix from reaction to measures: (507, 507)\n",
      "Reaction to metabolite matrix: (1078, 507)\n",
      "Metabolite to reaction matrix: (507, 1078)\n",
      "Training set X: (66, 34)\n",
      "Training set Y: (66, 507)\n",
      "S_int matrix (478, 507)\n",
      "S_ext matrix (507, 2663)\n",
      "Q matrix (507, 478)\n",
      "P matrix (507, 507)\n",
      "b_int vector (478,)\n",
      "b_ext vector (66, 2663)\n",
      "Sb matrix (507, 1078)\n",
      "c vector (507,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Verifying\n",
    "parameter = TrainingSet()\n",
    "parameter.load(trainingfile)\n",
    "print(trainingfile)\n",
    "parameter.printout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell has a completely different purpose than the rest of the notebook. It serves as a cell running Cobrapy with  provided values as inputs. These inputs are extracted from Reservoir Computing, you can see an example in the notebook `Build_Model_RC.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T16:09:31.986056Z",
     "iopub.status.busy": "2025-11-12T16:09:31.986056Z",
     "iopub.status.idle": "2025-11-12T16:09:39.939229Z",
     "shell.execute_reply": "2025-11-12T16:09:39.938197Z",
     "shell.execute_reply.started": "2025-11-12T16:09:31.986056Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1696 0.1542\n",
      "1 0.1340 0.1609\n",
      "2 0.1886 0.2010\n",
      "3 0.1990 0.1943\n",
      "4 0.0720 0.1135\n",
      "5 0.0924 0.1040\n",
      "6 0.0881 0.1068\n",
      "7 0.0900 0.1251\n",
      "8 0.1989 0.2010\n",
      "9 0.1054 0.1046\n",
      "10 0.2681 0.2412\n",
      "11 0.1576 0.1135\n",
      "12 0.1209 0.1943\n",
      "13 0.2729 0.2546\n",
      "14 0.2945 0.2479\n",
      "15 0.2386 0.2010\n",
      "16 0.2531 0.1787\n",
      "17 0.2606 0.2947\n",
      "18 0.2816 0.1542\n",
      "19 0.1351 0.1675\n",
      "20 0.1449 0.1675\n",
      "21 0.2409 0.2546\n",
      "22 0.2437 0.2657\n",
      "23 0.1059 0.1135\n",
      "24 0.1082 0.2010\n",
      "25 0.2451 0.3416\n",
      "26 0.3099 0.2189\n",
      "27 0.2000 0.2881\n",
      "28 0.2077 0.1318\n",
      "29 0.3837 0.3014\n",
      "30 0.2247 0.2256\n",
      "31 0.3520 0.2256\n",
      "32 0.2255 0.1943\n",
      "33 0.1340 0.2613\n",
      "34 0.2397 0.3126\n",
      "35 0.3654 0.3126\n",
      "36 0.1863 0.2144\n",
      "37 0.1612 0.2613\n",
      "38 0.3442 0.2657\n",
      "39 0.2964 0.3059\n",
      "40 0.4135 0.2724\n",
      "41 0.2561 0.1720\n",
      "42 0.3949 0.3014\n",
      "43 0.4205 0.2479\n",
      "44 0.3050 0.3349\n",
      "45 0.2315 0.1675\n",
      "46 0.2708 0.2546\n",
      "47 0.3351 0.3818\n",
      "48 0.2785 0.3014\n",
      "49 0.0765 0.2010\n",
      "50 0.0704 0.1068\n",
      "51 0.2095 0.2010\n",
      "52 0.1135 0.1251\n",
      "53 0.2193 0.2010\n",
      "54 0.3316 0.2479\n",
      "55 0.1368 0.1068\n",
      "56 0.1362 0.1318\n",
      "57 0.1074 0.1609\n",
      "58 0.2277 0.1943\n",
      "59 0.2021 0.1609\n",
      "60 0.2275 0.1609\n",
      "61 0.2131 0.2412\n",
      "62 0.2624 0.2077\n",
      "63 0.1862 0.2189\n",
      "64 0.1688 0.2546\n",
      "65 0.3621 0.3483\n",
      "66 0.2549 0.2122\n",
      "67 0.2429 0.2546\n",
      "68 0.1936 0.1720\n",
      "69 0.3361 0.2724\n",
      "70 0.3688 0.3349\n",
      "71 0.1765 0.1318\n",
      "72 0.1585 0.1943\n",
      "73 0.1538 0.1135\n",
      "74 0.1887 0.1542\n",
      "75 0.1655 0.2010\n",
      "76 0.1706 0.2077\n",
      "77 0.2155 0.2256\n",
      "78 0.1549 0.1675\n",
      "79 0.3022 0.2189\n",
      "80 0.2706 0.2546\n",
      "81 0.2405 0.2947\n",
      "82 0.3362 0.3014\n",
      "83 0.3027 0.3595\n",
      "84 0.1924 0.1787\n",
      "85 0.1674 0.2077\n",
      "86 0.3255 0.3885\n",
      "87 0.2519 0.2590\n",
      "88 0.3355 0.3193\n",
      "89 0.2919 0.2412\n",
      "90 0.3048 0.3349\n",
      "91 0.2370 0.1943\n",
      "92 0.2977 0.3416\n",
      "93 0.2461 0.2144\n",
      "94 0.2310 0.3014\n",
      "95 0.2037 0.1251\n",
      "96 0.3402 0.2412\n",
      "97 0.2041 0.2881\n",
      "98 0.1665 0.2546\n",
      "99 0.1320 0.1318\n",
      "100 0.2731 0.2256\n",
      "101 0.3785 0.3595\n",
      "102 0.2321 0.3126\n",
      "103 0.3675 0.2724\n",
      "104 0.2712 0.2189\n",
      "105 0.2610 0.2412\n",
      "106 0.2469 0.2657\n",
      "107 0.3929 0.3818\n",
      "108 0.3630 0.4353\n",
      "109 0.1949 0.1675\n",
      "scaler 2.50 R2 0.5182 \n"
     ]
    }
   ],
   "source": [
    "# This cell run FBA on a provided training and compute R2 between\n",
    "# provided objective and calculated objective\n",
    "# R2 = 1 when the training set was generated by FBA, but may be different than 1\n",
    "# when the training set is an experimental one\n",
    "# For exprimental training set medium input fluxes can be scaled by a value\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# What you can change \n",
    "seed = 10\n",
    "np.random.seed(seed=seed)  \n",
    "cobraname = 'iML1515_EXP'  # name of the model \n",
    "mediumbound = 'UB' # a must, exact bounds unknown\n",
    "mediumname = 'iML1515_EXP' # name of experimental file, for out-of-the-box FBA\n",
    "# mediumname = 'iML1515_UB_AMN_QP_RC_AMN_solution_for_Cobra_train' # for running Cobra with RC training points as inputs\n",
    "# mediumname = 'iML1515_UB_AMN_QP_RC_AMN_solution_for_Cobra_pred' # for running Cobra with RC predictions as inputs\n",
    "method = 'EXP' # FBA, pFBA or EXP\n",
    "# End of What you can change\n",
    "\n",
    "# Get data\n",
    "cobrafile =  DIRECTORY+'Dataset_input/'+cobraname\n",
    "mediumfile = DIRECTORY+'Dataset_input/'+mediumname\n",
    "parameter = TrainingSet(cobraname=cobrafile, \n",
    "                        mediumname=mediumfile, mediumbound=mediumbound, mediumsize=38, \n",
    "                        method=method,verbose=False)\n",
    "#Â scaler_list = [2.0, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3.0] # test different scalers\n",
    "scaler_list = [2.5] # best scaler for out-of-the box FBA\n",
    "# scaler_list = [1] # for running Cobra with RC training inputs, see mediumname\n",
    "\n",
    "# regression cobra vs. true values\n",
    "L = parameter.X.shape[0]\n",
    "for scaler in scaler_list:\n",
    "    Y = {}\n",
    "    for i in range(L):\n",
    "        inf = {r.id: 0 for r in parameter.model.reactions}\n",
    "        for j in range(len(parameter.medium)):\n",
    "            #print(j, parameter.medium[j],parameter.X[i,j], len(parameter.model.reactions))\n",
    "            eps = 1.0e-4 if parameter.X[i,j] < 1.0e-4 else 0\n",
    "            inf[parameter.medium[j]] = scaler * parameter.X[i,j] + eps\n",
    "        out,Y[i] = run_cobra(parameter.model, parameter.objective, inf, method='pFBA', verbose=False)\n",
    "        print(\"%d %.4f %.4f\" % (i, parameter.Y[i], Y[i]))\n",
    "\n",
    "    Y = list(Y.values())\n",
    "    r2 = r2_score(parameter.Y[0:L], Y[0:L], multioutput='variance_weighted')\n",
    "    print('scaler %.2f R2 %.4f ' % (scaler, r2))\n",
    "# np.array(Y).tofile(\"Result/Cobra_alone.csv\") # to uncomment if cobra alone saved in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T16:09:39.940234Z",
     "iopub.status.busy": "2025-11-12T16:09:39.939229Z",
     "iopub.status.idle": "2025-11-12T16:10:04.707695Z",
     "shell.execute_reply": "2025-11-12T16:10:04.707604Z",
     "shell.execute_reply.started": "2025-11-12T16:09:39.940234Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 0.9597 0.9538 0.9709\n"
     ]
    }
   ],
   "source": [
    "# This cell run FBA for P. putida model on a provided training and compute Accuracy between\n",
    "# provided objective and calculated objective\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# What you can change \n",
    "seed = 10\n",
    "np.random.seed(seed=seed)  \n",
    "cobraname = 'IJN1463_10_UB'  # name of the model \n",
    "mediumbound = 'UB' # a must, exact bounds unknown\n",
    "mediumname = 'IJN1463_EXP' # for running Cobra with Exp file\n",
    "mediumname = 'IJN1463_10_UB_AMN_QP_for_Cobra_train' # for running Cobra with RC file\n",
    "method = 'EXP' # FBA, pFBA or EXP\n",
    "L = 166 # split nitrogen (nh4) carbon (glucose)\n",
    "# End of What you can change\n",
    "\n",
    "# Get data\n",
    "cobrafile =  DIRECTORY+'Dataset_input/'+cobraname\n",
    "mediumfile = DIRECTORY+'Dataset_input/'+mediumname\n",
    "parameter = TrainingSet(cobraname=cobrafile, \n",
    "                        mediumname=mediumfile,\n",
    "                        mediumbound=mediumbound, mediumsize=196, \n",
    "                        method=method,verbose=False)\n",
    "\n",
    "# Input medium are scaled by 10 for EXP file\n",
    "scalerX = 1 if 'AMN' in mediumname else 10\n",
    "Y = {}\n",
    "for i in range(parameter.X.shape[0]):\n",
    "    inf = {r.id: 0 for r in parameter.model.reactions}\n",
    "    for j in range(len(parameter.medium)):\n",
    "        eps = 1.0e-4 if parameter.X[i,j] < 1.0e-4 else 0\n",
    "        inf[parameter.medium[j]] = scalerX * parameter.X[i,j] + eps\n",
    "    try:\n",
    "         _, Y[i] = run_cobra(parameter.model, parameter.objective, inf, method='FBA', verbose=False)\n",
    "    except:\n",
    "        _, Y[i] = 0, 0\n",
    "    #print(\"%d %.0f %.4f\" % (i, parameter.Y[i], Y[i]))\n",
    "        \n",
    "\n",
    "# Accuracies corrected with reactions not in the model\n",
    "# TN: 23 (28) for C (N) total=51  (reaction not in the model and no grow)\n",
    "# FN: 3 (1) for C (N) total=4 (reaction not in the model and but grow)\n",
    "y_true = np.transpose(parameter.Y)[0] \n",
    "y_pred = np.asarray([1 if Y[i] > 0.01 else 0 for i in range(len(Y.values()))])\n",
    "accall = accuracy_score(y_true, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "accall = (tp+tn+51)/(tn+51+fp+fn+4+tp)\n",
    "tn, fp, fn, tp = confusion_matrix(y_true[:L], y_pred[:L]).ravel()\n",
    "accnh4 = (tp+tn+28)/(tn+28+fp+fn+1+tp)       \n",
    "tn, fp, fn, tp = confusion_matrix(y_true[L:], y_pred[L:]).ravel()\n",
    "accglu = (tp+tn+23)/(tn+23+fp+fn+3+tp)       \n",
    "print('Acc %.4f %.4f %.4f' % (accall, accnh4, accglu))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
