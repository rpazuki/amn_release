{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fd7e165",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-12T17:47:27.659874Z",
     "iopub.status.busy": "2025-11-12T17:47:27.659874Z",
     "iopub.status.idle": "2025-11-12T17:47:32.871848Z",
     "shell.execute_reply": "2025-11-12T17:47:32.871764Z",
     "shell.execute_reply.started": "2025-11-12T17:47:27.659874Z"
    },
    "executionInfo": {
     "elapsed": 117260,
     "status": "ok",
     "timestamp": 1664526767265,
     "user": {
      "displayName": "Leon Faure",
      "userId": "06483081905364613855"
     },
     "user_tz": -120
    },
    "id": "BYwheAEcr-ME",
    "outputId": "8ba41a54-6751-4c00-ed1a-938db78cafb6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# In this case the local root of the repo is our working directory\n",
    "DIRECTORY = './'\n",
    "font = 'arial'\n",
    "\n",
    "from Library.Build_Model import *\n",
    "\n",
    "# We declare this function here and not in the\n",
    "# function-storing python file to modify it easily\n",
    "# as it can change the printouts of the methods\n",
    "def printout(filename, Stats, model, time): \n",
    "    # printing Stats\n",
    "    print('Stats for %s CPU-time %.4f' % (filename, time))\n",
    "    print('R2 = %.4f (+/- %.4f) Constraint = %.4f (+/- %.4f)' % \\\n",
    "          (Stats.train_objective[0], Stats.train_objective[1],\n",
    "           Stats.train_loss[0], Stats.train_loss[1]))\n",
    "    print('Q2 = %.4f (+/- %.4f) Constraint = %.4f (+/- %.4f)' % \\\n",
    "          (Stats.test_objective[0], Stats.test_objective[1],\n",
    "           Stats.test_loss[0], Stats.test_loss[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eace6cc",
   "metadata": {},
   "source": [
    "## Create the dataset from the paper example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8f672ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file name: ./Dataset_model/iML1515_EXP_UB_my_test\n",
      "reduced model: False\n",
      "medium file name: ./Dataset_input/iML1515_EXP\n",
      "medium bound: UB\n",
      "list of reactions in objective: ['BIOMASS_Ec_iML1515_core_75p37M']\n",
      "method: EXP\n",
      "trainingsize: 110\n",
      "list of medium reactions: 38\n",
      "list of medium levels: 0\n",
      "list of medium values: 0\n",
      "ratio of variable medium turned on: 0\n",
      "list of measured reactions: 543\n",
      "Stoichiometric matrix (1080, 543)\n",
      "Boundary matrix from reactions to medium: (38, 543)\n",
      "Measurement matrix from reaction to measures: (543, 543)\n",
      "Reaction to metabolite matrix: (1080, 543)\n",
      "Metabolite to reaction matrix: (543, 1080)\n",
      "Training set X: (110, 38)\n",
      "Training set Y: (110, 1)\n",
      "S_int matrix (478, 543)\n",
      "S_ext matrix (543, 2703)\n",
      "Q matrix (543, 478)\n",
      "P matrix (543, 543)\n",
      "b_int vector (478,)\n",
      "b_ext vector (110, 2703)\n",
      "Sb matrix (543, 1080)\n",
      "c vector (543,)\n"
     ]
    }
   ],
   "source": [
    "# Generate training set for E coli iML1515 experimental file \n",
    "\n",
    "# What you can change\n",
    "seed = 10\n",
    "np.random.seed(seed=seed)  # seed for random number generator\n",
    "cobraname = 'iML1515_EXP'  # name of the model here a reduced iML1515 model\n",
    "mediumbound = 'UB' # a must exact bounds unknown\n",
    "mediumname = 'iML1515_EXP' # name of experimental file \n",
    "method    = 'EXP' # FBA, pFBA or EXP\n",
    "reduce = False # Set at True if you want to reduce the model\n",
    "# End of What you can change\n",
    "\n",
    "# Get data\n",
    "cobrafile = DIRECTORY+'Dataset_input/'+cobraname\n",
    "mediumfile  = DIRECTORY+'Dataset_input/'+mediumname\n",
    "parameter = TrainingSet(cobraname=cobrafile, \n",
    "                        mediumname=mediumfile, mediumbound=mediumbound, mediumsize=38, \n",
    "                        method=method,verbose=False)\n",
    "\n",
    "# Saving file\n",
    "trainingfile  = DIRECTORY+'Dataset_model/'+mediumname+'_'+parameter.mediumbound + \"_my_test\"\n",
    "parameter.save(trainingfile, reduce=reduce)\n",
    "\n",
    "# Verifying\n",
    "parameter = TrainingSet()\n",
    "parameter.load(trainingfile)\n",
    "parameter.printout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03780dd6",
   "metadata": {},
   "source": [
    "#### Check the provided targets (Y or observed) are the same as the measured values in the saved dataset (originaly from experimental csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af6c3652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True if the parameter.Y is equal to average growth rate in the experimental data: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_exp_data = pd.read_csv(cobrafile + \".csv\")\n",
    "print(\"True if the parameter.Y is equal to average growth rate in the experimental data: \" \n",
    "      f\"{np.all(df_exp_data['GR_AVG'].values == parameter.Y.flatten())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b573d8",
   "metadata": {},
   "source": [
    "#### Check the provided inputs (X or medium) are the same as the values in the saved dataset (originaly from experimental csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "721be62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True if the parameter.Y is equal to average growth rate in the experimental data: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_exp_data = pd.read_csv(cobrafile + \".csv\")\n",
    "print(\"True if the parameter.Y is equal to average growth rate in the experimental data: \" \n",
    "    f\"{np.all(parameter.X == df_exp_data.iloc[:, :-1].values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9a2501",
   "metadata": {},
   "source": [
    "## Loading the experminatl dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f237a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of reactions:  543 1\n",
      "number of metabolites:  1080\n",
      "filtered measurements size:  1\n"
     ]
    }
   ],
   "source": [
    " \n",
    "trainname = 'iML1515_EXP_UB_my_test' \n",
    "timestep = 1\n",
    "# End of What you can change\n",
    "\n",
    "# Create model 100% for training 0% for testing\n",
    "trainingfile = DIRECTORY+'Dataset_model/'+trainname\n",
    "model = Neural_Model(trainingfile = trainingfile, \n",
    "            objective=['BIOMASS_Ec_iML1515_core_75p37M'], \n",
    "            model_type = 'AMN_LP',\n",
    "            scaler = True,\n",
    "            timestep = timestep, learn_rate=0.001,\n",
    "            n_hidden = 1, hidden_dim = 500,\n",
    "            #train_rate = 1.0e-2,\n",
    "            epochs = 3, xfold = 1, \n",
    "            verbose=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16cff58",
   "metadata": {},
   "source": [
    "#### Check the provided targets (Y or observed) is the same as the measured values in the AMN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4501a9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True if the parameter.Y is equal to average growth rate in the experimental data: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_exp_data = pd.read_csv(cobrafile + \".csv\")\n",
    "print(\"True if the parameter.Y is equal to average growth rate in the experimental data: \" \n",
    "      f\"{np.all(df_exp_data['GR_AVG'].values == model.Y.flatten())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a25bf21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input model.X shape: (110, 38)\n",
      "Input model.Y shape: (110, 1)\n",
      "parameter.b_int shape: (478,)\n",
      "parameter.b_ext shape: (110, 2703)\n",
      "AMN scaler 1.0\n",
      "b_int.shape:  (110, 478)\n",
      "concatenated X and b_int shape: (110, 516)\n",
      "b_ext.shape:  (110, 2703)\n",
      "concatenated X and b_ext shape: (110, 3219)\n",
      "LP input shape (110, 3219) (110, 4)\n",
      "Outputs inputs X shape: (110, 3219) composed of [X (from model.X), b_int.T (repeated vertically with the same size of model.X), b_ext] (LP specific, check for other models as well)\n",
      "Outputs targets Y shape: (110, 4) composed of [Y (from model.Y), SV constraints,  Pin constraints, V ≥ 0 constraints]\n"
     ]
    }
   ],
   "source": [
    "param = copy.copy(model)\n",
    "print(\"Input model.X shape:\", model.X.shape)\n",
    "print(\"Input model.Y shape:\", model.Y.shape)\n",
    "print(\"parameter.b_int shape:\", parameter.b_int.shape)\n",
    "print(\"parameter.b_ext shape:\", parameter.b_ext.shape)\n",
    "X, Y = input_AMN(param, verbose=True) # or  model_input(param, verbose=True)\n",
    "print(\"Outputs inputs X shape:\", X.shape, \"composed of [X (from model.X), b_int.T (repeated vertically with the same size of model.X), b_ext] (LP specific, check for other models as well)\")\n",
    "print(\"Outputs targets Y shape:\", Y.shape, \"composed of [Y (from model.Y), SV constraints,  Pin constraints, V ≥ 0 constraints]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7badc2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMN scaler 1.0\n",
      "LP input shape (110, 3219) (110, 4)\n",
      "----------------------------------- AMN_LP\n",
      "Dense layer n_hidden, hidden_dim, output_dim, activation, trainable: 1 500 543 relu True\n",
      "Dense layer n_hidden, hidden_dim, output_dim, activation, trainable: 1 500 2703 linear True\n",
      "AMN output shapes for PoutV, SV, PinV, Vpos, V, outputs (None, 1) (None, 1) (None, 1) (None, 1) (None, 543) (None, 1090)\n",
      "nbr parameters: 1665246\n",
      "---------- 1\n",
      "Loss out on V0:  0.2330754\n",
      "Loss constraint on V0:  3.0847117e-05\n",
      "Loss all on V0:  0.015381853\n",
      "Loss out on Vf:  10.220672\n",
      "Loss constraint on Vf:  1.2536824\n",
      "Loss all on Vf:  30.185303\n",
      "Distance V0 to Vf 2567.872559: \n",
      "looping bad training iter=0 r2=-16450.2407\n",
      "---------- 1\n",
      "Loss out on V0:  0.2330754\n",
      "Loss constraint on V0:  3.0847117e-05\n",
      "Loss all on V0:  0.015381853\n",
      "Loss out on Vf:  10.220672\n",
      "Loss constraint on Vf:  1.2536824\n",
      "Loss all on Vf:  30.185303\n",
      "Distance V0 to Vf 2567.872559: \n",
      "train = -16450.24 test = -16450.24 loss-train = 1.253682 loss-test = 1.253682 iter=0\n"
     ]
    }
   ],
   "source": [
    "reservoir, pred, stats, _ = train_evaluate_model(model, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c359a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
