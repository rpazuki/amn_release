{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fd7e165",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-12T17:47:27.659874Z",
     "iopub.status.busy": "2025-11-12T17:47:27.659874Z",
     "iopub.status.idle": "2025-11-12T17:47:32.871848Z",
     "shell.execute_reply": "2025-11-12T17:47:32.871764Z",
     "shell.execute_reply.started": "2025-11-12T17:47:27.659874Z"
    },
    "executionInfo": {
     "elapsed": 117260,
     "status": "ok",
     "timestamp": 1664526767265,
     "user": {
      "displayName": "Leon Faure",
      "userId": "06483081905364613855"
     },
     "user_tz": -120
    },
    "id": "BYwheAEcr-ME",
    "outputId": "8ba41a54-6751-4c00-ed1a-938db78cafb6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In this case the local root of the repo is our working directory\n",
    "DIRECTORY = './'\n",
    "font = 'arial'\n",
    "\n",
    "\n",
    "from Library.Build_Model import *\n",
    "\n",
    "# We declare this function here and not in the\n",
    "# function-storing python file to modify it easily\n",
    "# as it can change the printouts of the methods\n",
    "def printout(V, Stats, model): \n",
    "    # printing Stats\n",
    "    print(\"R2 = %.2f (+/- %.2f) Constraint = %.2f (+/- %.2f)\" % \\\n",
    "          (Stats.train_objective[0], Stats.train_objective[1],\n",
    "           Stats.train_loss[0], Stats.train_loss[1]))\n",
    "    Vout = tf.convert_to_tensor(np.float32(model.Y))\n",
    "    Loss_norm, dLoss = Loss_Vout(V, model.Pout, Vout)\n",
    "    print('Loss Targets', np.mean(Loss_norm))\n",
    "    Loss_norm, dLoss = Loss_SV(V, model.S)\n",
    "    print('Loss SV', np.mean(Loss_norm))\n",
    "    Vin = tf.convert_to_tensor(np.float32(model.X))\n",
    "    Pin = tf.convert_to_tensor(np.float32(model.Pin))\n",
    "    if Vin.shape[1] == model.S.shape[1]: # special case\n",
    "        Vin  = tf.linalg.matmul(Vin, tf.transpose(Pin), b_is_sparse=True)\n",
    "    Loss_norm, dLoss = Loss_Vin(V, model.Pin, Vin, model.mediumbound,model)\n",
    "    print('Loss Vin bound', np.mean(Loss_norm))\n",
    "    Loss_norm, dLoss = Loss_Vpos(V, model)\n",
    "    print('Loss V positive', np.mean(Loss_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2224212c",
   "metadata": {
    "id": "zjsc0wvNS9ZP",
    "tags": []
   },
   "source": [
    "# Mechanistic Models\n",
    "\n",
    "# Examples with non-trainable mechanistic models, using FBA simulated training sets\n",
    "\n",
    "In both LP and QP solver, one can change the `trainname` suffix (EB or UB) to use exact or upper bounds as inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec0d7ce",
   "metadata": {},
   "source": [
    "## LP solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f451057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training file: ./Dataset_model/e_coli_core_EB\n",
      "model type: MM_LP\n",
      "model scaler: 0.0\n",
      "model input dim: 20\n",
      "model output dim: 1\n",
      "model medium bound: EB\n",
      "timestep: 10000\n",
      "training set size (10, 20) (10, 1)\n",
      "LP-Loss 1 0.2272104 0.07015557\n",
      "LP-Loss 10 0.15282075 0.055338588\n",
      "LP-Loss 100 0.05627328 0.031071583\n",
      "LP-Loss 1000 0.00066465396 0.00017357188\n",
      "LP-Loss 2000 6.618473e-05 0.000107279615\n",
      "LP-Loss 3000 1.7334908e-06 3.7169455e-06\n",
      "LP-Loss 4000 4.3478298e-07 1.041795e-06\n",
      "LP-Loss 5000 1.3090464e-07 2.7213605e-07\n",
      "LP-Loss 6000 9.06163e-08 2.6308328e-07\n",
      "LP-Loss 7000 8.9164594e-08 2.672046e-07\n",
      "LP-Loss 8000 2.6347433e-08 7.9037285e-08\n",
      "LP-Loss 9000 3.8238204e-10 1.1460827e-09\n",
      "LP-Loss 10000 2.013187e-12 5.1632383e-12\n",
      "AMN output shapes for PoutV, SV, PinV, Vpos, V, outputs (10, 1) (10, 1) (10, 1) (10, 1) (10, 154) (10, 312)\n",
      "R2 = 1.00 (+/- 0.00) Constraint = 0.00 (+/- 0.00)\n",
      "Loss Targets 1.5377998e-06\n",
      "Loss SV 6.4773485e-07\n",
      "Loss Vin bound 0.0\n",
      "Loss V positive 7.3044006e-09\n"
     ]
    }
   ],
   "source": [
    "# Run Mechanistic model (no training) QP (quadratic program) or LP (linear program)\n",
    "# using E. coli core simulation training sets and EB (or UB) bounds\n",
    "\n",
    "# What you can change\n",
    "seed = 10\n",
    "np.random.seed(seed=seed)  \n",
    "trainname = 'e_coli_core_EB' # the training set file name\n",
    "size = 10 # number of runs must be lower than the number of element in trainname\n",
    "timestep = int(1.0e4) # LP 1.0e4 QP 1.0e5\n",
    "learn_rate = 0.3 # LP 0.3 QP 1.0\n",
    "decay_rate = 0.9 # only in QP, UB 0.333 EB 0.9\n",
    "# End of What you can change\n",
    "\n",
    "# Create model and run GD for X and Y randomly drawn from trainingfile\n",
    "trainingfile = DIRECTORY+'Dataset_model/'+trainname\n",
    "model = Neural_Model(trainingfile = trainingfile, \n",
    "              objective=['BIOMASS_Ecoli_core_w_GAM'], \n",
    "              model_type = 'MM_LP', \n",
    "              timestep = timestep, \n",
    "              learn_rate = learn_rate, \n",
    "              decay_rate = decay_rate)\n",
    "\n",
    "# Select a random subset of the training set (of specified size)\n",
    "# With LP we also have to change b_ext and b_int accordingly\n",
    "ID = np.random.choice(model.X.shape[0], size, replace=False)\n",
    "model.X, model.Y = model.X[ID,:], model.Y[ID,:]\n",
    "if model.mediumbound == 'UB':\n",
    "    model.b_ext = model.b_ext[ID,:]\n",
    "if model.mediumbound == 'EB':\n",
    "    model.b_int = model.b_int[ID,:]\n",
    "\n",
    "# Prints a summary of the model before running\n",
    "model.printout()\n",
    "\n",
    "# Runs the appropriate method\n",
    "Ypred, Stats = MM_LP(model, verbose=True)\n",
    "\n",
    "# Printing results\n",
    "printout(Ypred, Stats, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f90ab06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 154), (0, 0), (0, 0))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ypred.shape, Stats.test_loss, Stats.test_objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f5bd9b",
   "metadata": {},
   "source": [
    "## QP solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a8cce24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training file: ./Dataset_model/e_coli_core_EB\n",
      "model type: MM_QP\n",
      "model scaler: 0.0\n",
      "model input dim: 20\n",
      "model output dim: 1\n",
      "model medium bound: EB\n",
      "timestep: 100000\n",
      "training set size (10, 20) (10, 1)\n",
      "QP-Loss 1 0.2272104 0.07015557\n",
      "QP-Loss 10 0.20700264 0.06390637\n",
      "QP-Loss 100 0.04306359 0.012898573\n",
      "QP-Loss 1000 0.0087860245 0.0027652902\n",
      "QP-Loss 2000 0.0054735364 0.0017401526\n",
      "QP-Loss 3000 0.004210529 0.0013475176\n",
      "QP-Loss 4000 0.0034903612 0.0011190932\n",
      "QP-Loss 5000 0.0030024287 0.00096238527\n",
      "QP-Loss 6000 0.0026370687 0.00084410864\n",
      "QP-Loss 7000 0.002346762 0.00074943283\n",
      "QP-Loss 8000 0.0021079662 0.00067134644\n",
      "QP-Loss 9000 0.001907666 0.0006060476\n",
      "QP-Loss 10000 0.001737138 0.0005507308\n",
      "QP-Loss 11000 0.0015902579 0.00050328433\n",
      "QP-Loss 12000 0.0014626117 0.00046219255\n",
      "QP-Loss 13000 0.0013508114 0.000426336\n",
      "QP-Loss 14000 0.0012524214 0.00039489506\n",
      "QP-Loss 15000 0.0011654419 0.00036718705\n",
      "QP-Loss 16000 0.0010882496 0.00034265674\n",
      "QP-Loss 17000 0.0010195186 0.000320866\n",
      "QP-Loss 18000 0.00095814106 0.00030144677\n",
      "QP-Loss 19000 0.00090316805 0.00028407678\n",
      "QP-Loss 20000 0.0008538038 0.00026849963\n",
      "QP-Loss 21000 0.00080937566 0.00025449926\n",
      "QP-Loss 22000 0.0007693035 0.00024189038\n",
      "QP-Loss 23000 0.00073310675 0.00023050728\n",
      "QP-Loss 24000 0.0007003824 0.00022018788\n",
      "QP-Loss 25000 0.0006707572 0.00021080546\n",
      "QP-Loss 26000 0.00064387283 0.00020227599\n",
      "QP-Loss 27000 0.0006194683 0.0001945837\n",
      "QP-Loss 28000 0.00059729966 0.00018771981\n",
      "QP-Loss 29000 0.0005771374 0.00018169355\n",
      "QP-Loss 30000 0.0005587075 0.0001764028\n",
      "QP-Loss 31000 0.00054180756 0.00017171908\n",
      "QP-Loss 32000 0.0005263373 0.00016758915\n",
      "QP-Loss 33000 0.0005121362 0.00016393958\n",
      "QP-Loss 34000 0.00049908285 0.00016071278\n",
      "QP-Loss 35000 0.00048708386 0.00015786059\n",
      "QP-Loss 36000 0.00047601285 0.0001553327\n",
      "QP-Loss 37000 0.00046577453 0.00015309735\n",
      "QP-Loss 38000 0.00045629014 0.00015113084\n",
      "QP-Loss 39000 0.0004474783 0.00014939481\n",
      "QP-Loss 40000 0.0004392651 0.00014785284\n",
      "QP-Loss 41000 0.00043158344 0.00014647719\n",
      "QP-Loss 42000 0.00042437218 0.00014524448\n",
      "QP-Loss 43000 0.00041758097 0.00014413433\n",
      "QP-Loss 44000 0.00041116495 0.00014313354\n",
      "QP-Loss 45000 0.00040508405 0.00014222637\n",
      "QP-Loss 46000 0.00039930487 0.0001413989\n",
      "QP-Loss 47000 0.00039379735 0.00014064302\n",
      "QP-Loss 48000 0.00038854394 0.0001399445\n",
      "QP-Loss 49000 0.00038352518 0.00013929314\n",
      "QP-Loss 50000 0.00037871295 0.0001386832\n",
      "QP-Loss 51000 0.0003740879 0.00013811038\n",
      "QP-Loss 52000 0.00036963148 0.00013756953\n",
      "QP-Loss 53000 0.00036532764 0.00013705573\n",
      "QP-Loss 54000 0.00036116198 0.00013656463\n",
      "QP-Loss 55000 0.0003571255 0.00013609484\n",
      "QP-Loss 56000 0.00035322574 0.00013563242\n",
      "QP-Loss 57000 0.00034945284 0.00013517385\n",
      "QP-Loss 58000 0.00034579582 0.00013471769\n",
      "QP-Loss 59000 0.00034224283 0.00013426575\n",
      "QP-Loss 60000 0.00033878535 0.00013381985\n",
      "QP-Loss 61000 0.00033541658 0.00013337756\n",
      "QP-Loss 62000 0.00033213192 0.00013294083\n",
      "QP-Loss 63000 0.00032892436 0.00013250811\n",
      "QP-Loss 64000 0.0003257883 0.00013208044\n",
      "QP-Loss 65000 0.00032271954 0.0001316548\n",
      "QP-Loss 66000 0.00031971443 0.00013123357\n",
      "QP-Loss 67000 0.00031676757 0.00013081139\n",
      "QP-Loss 68000 0.000313877 0.00013039233\n",
      "QP-Loss 69000 0.00031103956 0.00012997338\n",
      "QP-Loss 70000 0.0003082503 0.00012955558\n",
      "QP-Loss 71000 0.00030551068 0.0001291414\n",
      "QP-Loss 72000 0.00030281494 0.00012872717\n",
      "QP-Loss 73000 0.0003001645 0.00012831135\n",
      "QP-Loss 74000 0.00029755718 0.0001278935\n",
      "QP-Loss 75000 0.00029499194 0.00012747101\n",
      "QP-Loss 76000 0.000292467 0.00012704774\n",
      "QP-Loss 77000 0.00028998277 0.00012662061\n",
      "QP-Loss 78000 0.00028753624 0.00012619204\n",
      "QP-Loss 79000 0.0002851256 0.00012576387\n",
      "QP-Loss 80000 0.00028274924 0.00012533549\n",
      "QP-Loss 81000 0.000280405 0.0001249066\n",
      "QP-Loss 82000 0.0002780938 0.00012447574\n",
      "QP-Loss 83000 0.00027581543 0.0001240429\n",
      "QP-Loss 84000 0.00027357112 0.00012360937\n",
      "QP-Loss 85000 0.0002713569 0.00012317408\n",
      "QP-Loss 86000 0.00026917362 0.00012273775\n",
      "QP-Loss 87000 0.00026702162 0.00012230169\n",
      "QP-Loss 88000 0.00026489707 0.0001218659\n",
      "QP-Loss 89000 0.00026279961 0.00012142892\n",
      "QP-Loss 90000 0.00026072763 0.00012098842\n",
      "QP-Loss 91000 0.0002586814 0.00012054963\n",
      "QP-Loss 92000 0.00025666162 0.00012011218\n",
      "QP-Loss 93000 0.00025466568 0.000119673816\n",
      "QP-Loss 94000 0.00025269436 0.00011923525\n",
      "QP-Loss 95000 0.00025074877 0.00011880084\n",
      "QP-Loss 96000 0.0002488278 0.00011836711\n",
      "QP-Loss 97000 0.0002469318 0.000117935604\n",
      "QP-Loss 98000 0.0002450559 0.00011750414\n",
      "QP-Loss 99000 0.00024320139 0.00011707234\n",
      "QP-Loss 100000 0.00024137113 0.00011664238\n",
      "AMN output shapes for PoutV, SV, PinV, Vpos, V, outputs (10, 1) (10, 1) (10, 1) (10, 1) (10, 154) (10, 312)\n",
      "R2 = 1.00 (+/- 0.00) Constraint = 0.00 (+/- 0.00)\n",
      "Loss Targets 0.0014483153\n",
      "Loss SV 0.028404087\n",
      "Loss Vin bound 0.0\n",
      "Loss V positive 0.010033725\n"
     ]
    }
   ],
   "source": [
    "# Run Mechanistic model (no training) QP (quadratic program) or LP (linear program)\n",
    "# using E. coli core simulation training sets and EB (or UB) bounds\n",
    "\n",
    "# What you can change\n",
    "seed = 10\n",
    "np.random.seed(seed=seed)  \n",
    "trainname = 'e_coli_core_EB' # the training set file name\n",
    "size = 10 # number of runs must be lower than the number of element in trainname\n",
    "timestep = int(1.0e5) # LP 1.0e4 QP 1.0e5\n",
    "learn_rate = 1.0 # LP 0.3 QP 1.0\n",
    "decay_rate = 0.9 # only in QP, UB 0.333 EB 0.9\n",
    "# End of What you can change\n",
    "\n",
    "# Create model and run GD for X and Y randomly drawn from trainingfile\n",
    "trainingfile = DIRECTORY+'Dataset_model/'+trainname\n",
    "model = Neural_Model(trainingfile = trainingfile, \n",
    "              objective=['BIOMASS_Ecoli_core_w_GAM'], \n",
    "              model_type = 'MM_QP', \n",
    "              timestep = timestep, \n",
    "              learn_rate = learn_rate, \n",
    "              decay_rate = decay_rate)\n",
    "\n",
    "# Select a random subset of the training set (of specified size)\n",
    "ID = np.random.choice(model.X.shape[0], size, replace=False)\n",
    "model.X, model.Y = model.X[ID,:], model.Y[ID,:]\n",
    "\n",
    "# Prints a summary of the model before running\n",
    "model.printout()\n",
    "\n",
    "# Runs the appropriate method\n",
    "if model.model_type is 'MM_QP':\n",
    "    Ypred, Stats = MM_QP(model, verbose=True)\n",
    "\n",
    "# Printing results\n",
    "printout(Ypred, Stats, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47cd0c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 67), (154,), (1, 154), (20, 154), (72, 154), (72, 154), 'MM_QP')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.b_int.shape, model.b_ext.shape, model.Pout.shape, model.Pin.shape, model.S.shape, model.V2M.shape, model.model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ccb3f295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 154), 24, 1.0, None)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Pout.shape, np.argmax(model.Pout), model.Pout.flatten()[24], model.get_parameter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "45181c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td><strong>Reaction identifier</strong></td><td>BIOMASS_Ecoli_core_w_GAM</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Name</strong></td><td>Biomass Objective Function with GAM</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Memory address</strong></td>\n",
       "                <td>0x1473c3ac748</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Stoichiometry</strong></td>\n",
       "                <td>\n",
       "                    <p style='text-align:right'>1.496 3pg_c + 3.7478 accoa_c + 59.81 atp_c + 0.361 e4p_c + 0.0709 f6p_c + 0.129 g3p_c + 0.205 g6p_c + 0.2557 gln__L_c + 4.9414 glu__L_c + 59.81 h2o_c + 3.547 nad_c + 13.0279 nadph_c + 1.7867 oaa_c...</p>\n",
       "                    <p style='text-align:right'>1.496 3-Phospho-D-glycerate + 3.7478 Acetyl-CoA + 59.81 ATP C10H12N5O13P3 + 0.361 D-Erythrose 4-phosphate + 0.0709 D-Fructose 6-phosphate + 0.129 Glyceraldehyde 3-phosphate + 0.205 D-Glucose...</p>\n",
       "                </td>\n",
       "            </tr><tr>\n",
       "                <td><strong>GPR</strong></td><td></td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Lower bound</strong></td><td>0.0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Upper bound</strong></td><td>1000.0</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<Reaction BIOMASS_Ecoli_core_w_GAM at 0x1473c3ac748>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter = TrainingSet()\n",
    "parameter.load(model.trainingfile)\n",
    "parameter.model.reactions[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53f53d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(model.X[0], model.Pin).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "874a86e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Pin[15:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4546bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
